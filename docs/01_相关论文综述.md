# CCF-A 相关论文综述：面向大模型训练的智能跨域调度

> 文档版本：v1.0
> 更新日期：2026-01-26
> 作者：Claude Code

---

## 1. 概述

本文档整理了近年来（2023-2025）CCF-A类会议/期刊中与大模型分布式训练调度相关的重要论文，涵盖以下主题：

- 跨数据中心/跨域分布式训练
- GPU集群调度算法
- 强化学习驱动的调度优化
- 流水线并行与通信优化

> **核心假设**: 本研究假设**同构算力环境**（各域 GPU 型号相同），核心挑战聚焦于**跨域网络动态性**和**通信优化**。

---

## 2. 跨数据中心分布式训练（核心相关）

### 2.1 MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters

**会议**: OSDI 2024
**链接**: [PDF](https://www.usenix.org/system/files/osdi24-choudhury.pdf) | [USENIX](https://www.usenix.org/conference/osdi24/presentation/choudhury)

**核心贡献**:
- 提出了面向地理分布式数据中心的ML训练全局调度系统
- 考虑了跨数据中心的网络带宽、延迟和成本约束
- 实现了训练任务在多个数据中心之间的智能分配

**与本课题关联**:
- 直接对应课题3"智能跨域调度算法设计"的核心问题
- 其分层调度思想可借鉴用于"城间调度"与"城内调度"的设计

---

### 2.2 Sailor: Automating Distributed Training over Dynamic Heterogeneous and Geo-distributed Clusters

**会议**: SOSP 2025
**链接**: [PDF](https://anakli.inf.ethz.ch/papers/sailor_sosp25.pdf) | [ResearchGate](https://www.researchgate.net/publication/391120135)

**核心贡献**:
- 自动化处理动态变化的地理分布式集群上的分布式训练
- 支持集群资源的动态变化（节点加入/退出）
- 提出了自适应的并行策略调整机制

**与本课题关联**:
- 属于相关工作（课题4侧重容错），本课题仅借鉴其**动态适应机制**
- 不引入其“异构资源”假设，保持**同构算力环境**

---

### 2.3 CrossPipe: Towards Optimal Pipeline Schedules for Cross-Datacenter Training

**链接**: [arXiv](https://arxiv.org/abs/2507.00217)

**核心贡献**:
- 针对跨数据中心训练场景优化流水线调度
- 考虑了跨域网络延迟对流水线效率的影响
- 提出了跨数据中心的最优流水线调度算法

**与本课题关联**:
- 直接对应课题3中的跨域通信成本优化目标
- 流水线调度策略可集成到调度算法中

---

### 2.4 FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression

**链接**: [arXiv](https://arxiv.org/abs/2410.12707)

**核心贡献**:
- 去中心化的LLM训练系统设计
- 自适应压缩技术减少跨域通信开销
- 支持地理分布式GPU资源的协同训练

**与本课题关联**:
- 自适应压缩技术可用于降低跨域通信成本
- 去中心化架构思想可借鉴

---

### 2.5 SpanTrain: Highly Efficient Cross-domain Model Distributed Training

**链接**: [arXiv](https://arxiv.org/pdf/2505.15536)

**核心贡献**:
- 高效的跨域模型分布式训练方法
- 优化跨域数据传输和同步机制

**与本课题关联**:
- 跨域训练效率优化方法可直接借鉴

---

## 3. GPU集群调度算法

### 3.1 Crux: GPU-Efficient Communication Scheduling for Deep Learning Training

**会议**: SIGCOMM 2024
**链接**: [ACM](https://dl.acm.org/doi/10.1145/3651890.3672239) | [PDF](https://cs.stanford.edu/~keithw/sigcomm2024/sigcomm24-final380-acmpaginated.pdf)

**核心贡献**:
- 优化深度学习训练中的通信调度
- 提高GPU利用效率
- 减少通信与计算的重叠开销

**与本课题关联**:
- 通信调度优化技术可用于跨域场景
- GPU效率提升方法可集成到调度算法中

---

### 3.2 nnScaler: Constraint-Guided Parallelization Plan Generation

**会议**: OSDI 2024
**链接**: [PDF](https://www.usenix.org/system/files/osdi24-lin-zhiqi.pdf)

**核心贡献**:
- 基于约束的自动并行化方案生成
- 支持多种并行策略的组合优化
- 考虑硬件约束和模型特性

**与本课题关联**:
- 并行策略自动生成可用于跨域场景的策略选择
- 约束优化方法可借鉴

---

### 3.3 Rubick: Exploiting Job Reconfigurability for Deep Learning Cluster Scheduling

**链接**: [arXiv](https://arxiv.org/abs/2408.08586)

**核心贡献**:
- 利用任务可重配置性优化集群调度
- 动态调整任务的资源分配
- 提高集群整体利用率

**与本课题关联**:
- 任务重配置思想可用于跨域负载均衡
- 动态资源调整机制可借鉴

---

### 3.4 PAL: A Variability-Aware Policy for Scheduling ML Workloads in GPU Clusters

**链接**: [arXiv](https://arxiv.org/abs/2408.11919)

**核心贡献**:
- 考虑负载变化的调度策略
- 适应ML工作负载的动态特性

**与本课题关联**:
- 变化感知策略可用于处理跨域负载波动

---

### 3.5 Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling

**链接**: [arXiv](https://arxiv.org/html/2512.10980v1)

**核心贡献**:
- 动态多目标调度减少GPU集群碎片化
- 解决资源饥饿问题
- 多目标优化框架

**与本课题关联**:
- 多目标优化框架直接对应课题3的目标函数设计
- 碎片化处理方法可借鉴

---

## 4. 强化学习驱动的调度

### 4.1 Residual Scheduling: A New Reinforcement Learning Approach to Solving Job Shop Scheduling Problem

**会议**: NeurIPS 2023
**链接**: [OpenReview](https://openreview.net/forum?id=5uIL1E8h1E)

**核心贡献**:
- 提出残差调度的RL方法
- 解决作业车间调度问题
- 新颖的状态表示和动作空间设计

**与本课题关联**:
- RL调度方法论可借鉴
- 残差学习思想可用于增量调度决策

---

### 4.2 Decentralized Distributed Proximal Policy Optimization (DD-PPO) for HPC Scheduling

**链接**: [arXiv](https://arxiv.org/html/2505.03946v1)

**核心贡献**:
- 去中心化的分布式PPO算法
- 面向HPC多用户系统的调度
- 可扩展的RL训练框架

**与本课题关联**:
- PPO算法实现可直接参考
- 去中心化思想适用于跨域场景

---

### 4.3 SLA-MORL: SLA-Aware Multi-Objective Reinforcement Learning for HPC Resource Optimization

**链接**: [ADS](https://ui.adsabs.harvard.edu/abs/2025arXiv250803509A/abstract)

**核心贡献**:
- SLA感知的多目标强化学习
- HPC资源优化
- 多目标奖励函数设计

**与本课题关联**:
- 多目标RL框架直接对应课题3的RL调度算法设计
- SLA约束处理方法可借鉴

---

### 4.4 Network Contention-Aware Cluster Scheduling with Reinforcement Learning

**链接**: [arXiv](https://arxiv.org/abs/2310.20209)

**核心贡献**:
- 网络竞争感知的集群调度
- RL方法处理网络约束
- 考虑通信开销的调度决策

**与本课题关联**:
- 网络感知调度直接对应跨域通信成本优化
- RL状态空间设计可参考

---

### 4.5 Efficient LLM Scheduling by Learning to Rank

**链接**: [arXiv](https://arxiv.org/abs/2408.15792)

**核心贡献**:
- 基于学习排序的LLM调度
- 高效的调度决策机制

**与本课题关联**:
- LLM特定的调度优化方法可借鉴

---

### 4.6 Pipeline Parallelism Optimization with Deep Reinforcement Learning

**会议**: ICLR 2024 (under review)
**链接**: [OpenReview PDF](https://openreview.net/pdf/2f36f150633d055ac577e204f4d4f7d535d9ef72.pdf)

**核心贡献**:
- 提出 DRL-PP，用深度强化学习优化 pipeline 并行的分区与调度
- 结合图编码器（GCN）与递归分区器自动生成层划分
- 面向 pipeline 气泡与设备利用率进行联合优化

**与本课题关联**:
- 可作为“action → configuration（层划分/placement）”的 RL 先验
- GNN/GCN 编码方法可借鉴
- 局限：主要聚焦单集群/同域，不涉及跨域 WAN 动态性与分层调度

---

## 5. 流水线并行与通信优化

### 5.1 Seq1F1B: Efficient Sequence-Level Pipeline Parallelism for Large Language Model Training

**链接**: [arXiv](https://arxiv.org/abs/2406.03488)

**核心贡献**:
- 序列级流水线并行
- 高效的LLM训练调度
- 减少流水线气泡

**与本课题关联**:
- 流水线调度策略可用于跨域训练

---

### 5.2 Spindle: Efficient Distributed Training of Multi-Task Large Models via Wavefront Scheduling

**链接**: [arXiv](https://arxiv.org/pdf/2409.03365)

**核心贡献**:
- 波前调度策略
- 多任务大模型训练
- 高效的分布式训练

**与本课题关联**:
- 波前调度思想可用于跨域任务编排

---

### 5.3 Centauri: Enabling Efficient Scheduling for Communication-Computation Overlap

**链接**: [OpenReview](https://openreview.net/pdf/58de1dd82ec19b52473be7e4af3f6ed777c4a525.pdf)

**核心贡献**:
- 通信-计算重叠调度
- 通信分区技术
- 大模型训练效率优化

**与本课题关联**:
- 通信-计算重叠技术对跨域场景尤为重要
- 可用于隐藏跨域通信延迟

---

### 5.4 Scaling Deep Learning Training with MPMD Pipeline Parallelism

**链接**: [arXiv](https://arxiv.org/pdf/2412.14374)

**核心贡献**:
- MPMD（多程序多数据）流水线并行
- 大规模训练扩展

**与本课题关联**:
- MPMD 并行策略可用于跨域资源调度

---

### 5.5 Hyperion: Hierarchical Scheduling for Parallel LLM Acceleration in Multi-tier Networks

**链接**: [arXiv](https://arxiv.org/abs/2511.14450)

**核心贡献**:
- 分层调度架构
- 多层网络中的LLM加速
- 层次化资源管理

**与本课题关联**:
- 分层调度架构直接对应课题3的"城间-城内"分层设计
- 多层网络处理方法可借鉴

---

## 6. 论文分类总结

### 按主题分类

| 主题 | 论文数量 | 代表性论文 |
|------|----------|------------|
| 跨数据中心训练 | 5 | MAST, Sailor, CrossPipe |
| GPU集群调度 | 5 | Crux, nnScaler, Rubick |
| 强化学习调度 | 5 | Residual Scheduling, DD-PPO, SLA-MORL |
| 流水线/通信优化 | 5 | Seq1F1B, Spindle, Centauri |

### 按会议分类

| 会议/期刊 | 论文 |
|-----------|------|
| OSDI 2024 | MAST, nnScaler |
| SOSP 2025 | Sailor |
| SIGCOMM 2024 | Crux |
| NeurIPS 2023 | Residual Scheduling |
| arXiv (预印本) | 其他多篇 |

---

## 7. 对本课题的启示

### 7.1 技术路线建议

基于以上论文调研，建议本课题采用以下技术路线：

1. **分层调度架构**（参考 MAST, Hyperion）
   - 全局调度器负责城间任务分配
   - 本地调度器负责城内资源编排

2. **强化学习算法**（参考 DD-PPO, SLA-MORL）
   - 采用PPO作为基础算法
   - 设计多目标奖励函数

3. **通信优化**（参考 Crux, Centauri, CrossPipe）
   - 通信-计算重叠
   - 自适应压缩
   - 跨域流水线优化

4. **动态适应**（参考 Sailor, Rubick）
   - 任务可重配置
   - 资源动态调整

### 7.2 创新点建议

结合现有研究空白，建议本课题在以下方向寻求创新：

1. **面向"东数西算"的特定优化**
   - 现有研究多针对通用云环境
   - 可针对中国算力网络拓扑特点进行优化

2. **多租户QoS保障**
   - 现有研究较少考虑多租户场景
   - 可设计差异化SLA保障机制

3. **可解释性增强**
   - 现有RL调度算法可解释性差
   - 可结合规则引擎提供决策解释

---

## 8. 参考资源

### 论文集合
- [ML Systems Papers Collection](https://github.com/byungsoo-oh/ml-systems-papers)
- [Awesome ML for Combinatorial Optimization](https://github.com/Thinklab-SJTU/awesome-ml4co)

### 会议论文列表
- [OSDI 2024 Papers](https://paper.lingyunyang.com/reading-notes/conference/osdi-2024)
- [SIGCOMM 2024 Papers](https://paper.lingyunyang.com/reading-notes/conference/sigcomm-2024)
- [NSDI 2025 Technical Sessions](https://www.usenix.org/conference/nsdi25/technical-sessions)
